{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapping Github topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape the list of topics from Github\n",
    "\n",
    "Explain how you'll do it.\n",
    "\n",
    "- use requests to downlaod the page\n",
    "- user BS4 to parse and extract information\n",
    "- convert to a Pandas dataframe\n",
    "\n",
    "Let's write a function to download the page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Project Outline:\n",
    "- We are going to scrape https://github.com/topics\n",
    "- We will get a list of topics. For each topic, we'll get topic title, url, and description.\n",
    "- For each topic we will get top 25 repositories.\n",
    "- For each repository we will collect repo name, username, start, and url.\n",
    "- For each topic we will create .csv in this format\n",
    "- Format for csv file\n",
    "```\n",
    " Repo Name,Username,Stars,Repo URL\n",
    " three.js,mrdoob,69700,https://github.com/mrdoob/three.js\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import bs4 as bs\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a single function to:\n",
    "1. Get the list of topics from the topics page\n",
    "2. Get list of top repos from the individual topic pages\n",
    "3. For each topic create a csv of the top repos for the topic "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping topics from github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_title(doc):\n",
    "    selection_class = 'f3 lh-condensed mb-0 mt-1 Link--primary'\n",
    "    topic_title_tag = doc.find_all('p',{'class': selection_class })\n",
    "    \n",
    "    topic_title = []\n",
    "    for tag in topic_title_tag:\n",
    "        topic_title.append(tag.text)\n",
    "    return topic_title\n",
    "\n",
    "def get_topic_desc(doc):\n",
    "    desc_selector = 'f5 color-fg-muted mb-0 mt-1'\n",
    "    topic_desc_tag = doc.find_all('p',{'class':desc_selector})\n",
    "    topic_desc = []\n",
    "    for desc in topic_desc_tag:\n",
    "        topic_desc.append(desc.text.strip())\n",
    "    return topic_desc\n",
    "    \n",
    "    \n",
    "def get_topic_url(doc):\n",
    "    base_url = \"https://github.com\"\n",
    "    url_selector = 'no-underline flex-1 d-flex flex-column'\n",
    "    topic_link_tag = doc.find_all('a',{'class':url_selector})        \n",
    "    topic_urls = []\n",
    "    \n",
    "    for url in  topic_link_tag:\n",
    "        topic_urls.append(base_url+url['href'])\n",
    "    return topic_urls\n",
    "        \n",
    "def scrape_topics(num):\n",
    "    topic_url = 'https://github.com/topics?page={}'.format(num)\n",
    "    response = requests.get(topic_url)\n",
    "    if response.status_code !=200:\n",
    "        print(\"Process Stops restarting..........\")\n",
    "        !scrape_topics_repos()\n",
    "#         raise Exception('Failed to load the page {}'.format(topic_url))\n",
    "        \n",
    "    doc = bs.BeautifulSoup(response.text,'html.parser')\n",
    "    topics_dict = {\n",
    "        'title' : get_topic_title(doc),\n",
    "        'description' : get_topic_desc(doc),\n",
    "        'url' : get_topic_url(doc),\n",
    "        \n",
    "    }\n",
    "#     print(topics_dict)\n",
    "    return pd.DataFrame(topics_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping repositories for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_page(topic_url):\n",
    "    response = requests.get(topic_url)\n",
    "    if response.status_code !=200:\n",
    "        raise Exception('Failed to load the page {}'.format(topic_url))\n",
    "    topic_doc = bs.BeautifulSoup(response.text,'html.parser')\n",
    "    return topic_doc\n",
    "\n",
    "def get_repo_info(h3_tag, star_tags):\n",
    "    #gives all info about repository\n",
    "    base_url = \"https://github.com\"\n",
    "    a_tags = h3_tag.find_all('a')\n",
    "    username = a_tags[0].text.strip()\n",
    "    repo_name = a_tags[1].text.strip()\n",
    "    repo_url = repo_url = base_url + a_tags[1]['href']\n",
    "    star_count = parse_star_count(star_tags.text)\n",
    "    return username, repo_name, star_count, repo_url\n",
    "\n",
    "def parse_star_count(stars_count):\n",
    "    stars_str = stars_count.strip()\n",
    "    if stars_str[-1] == 'k':\n",
    "        return int(float(stars_str[:-1])*1000)\n",
    "    return (int(stars_str))\n",
    "        \n",
    "\n",
    "def get_topic_repos(topic_doc):\n",
    "    \n",
    "#     get h3 tag for repo name, url, etc.\n",
    "    h3_selection_class = 'f3 color-fg-muted text-normal lh-condensed'\n",
    "    repo_tags = topic_doc.find_all('h3',{'class': h3_selection_class})\n",
    "    \n",
    "#     get star tags\n",
    "    star_selector = 'Counter js-social-count'\n",
    "    star_tags = topic_doc.find_all('span',{'class': star_selector})\n",
    "    \n",
    "#     get repo info\n",
    "    topic_repos_dict = {\n",
    "        'username':[],\n",
    "        'repo_name':[],\n",
    "        'stars': [],\n",
    "        'repo_url':[]\n",
    "    }\n",
    "    for i in range (len(repo_tags)):\n",
    "        repo_info = get_repo_info(repo_tags[i],star_tags[i])\n",
    "        topic_repos_dict['username'].append(repo_info[0])\n",
    "        topic_repos_dict['repo_name'].append(repo_info[1])\n",
    "        topic_repos_dict['stars'].append(repo_info[2])\n",
    "        topic_repos_dict['repo_url'].append(repo_info[3])\n",
    "        \n",
    "#     put all in dataframe\n",
    "    topic_repos = pd.DataFrame(topic_repos_dict)\n",
    "    return topic_repos\n",
    "\n",
    "def scrape_topic(topic_url,path):\n",
    "\n",
    "    if os.path.exists(path):\n",
    "        print(\"File {} already exits.\".format(path))\n",
    "        return\n",
    "    topic_df = get_topic_repos(get_topic_page(topic_url))\n",
    "    topic_df.to_csv(path,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topics_repos():\n",
    "    for i in range(1,7):\n",
    "        topics_df = scrape_topics(i)\n",
    "\n",
    "        os.makedirs('Resultant Data Files',exist_ok = True)\n",
    "\n",
    "        for index,row in topics_df.iterrows():\n",
    "            print(\"Scrapping topic {}.\".format(row['title']))\n",
    "            scrape_topic(row['url'],'Resultant Data Files/{}.csv'.format(row['title']))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrapping topic 3D.\n",
      "File Resultant Data Files/3D.csv already exits.\n",
      "Scrapping topic Ajax.\n",
      "File Resultant Data Files/Ajax.csv already exits.\n",
      "Scrapping topic Algorithm.\n",
      "File Resultant Data Files/Algorithm.csv already exits.\n",
      "Scrapping topic Amp.\n",
      "File Resultant Data Files/Amp.csv already exits.\n",
      "Scrapping topic Android.\n",
      "File Resultant Data Files/Android.csv already exits.\n",
      "Scrapping topic Angular.\n",
      "File Resultant Data Files/Angular.csv already exits.\n",
      "Scrapping topic Ansible.\n",
      "File Resultant Data Files/Ansible.csv already exits.\n",
      "Scrapping topic API.\n",
      "File Resultant Data Files/API.csv already exits.\n",
      "Scrapping topic Arduino.\n",
      "File Resultant Data Files/Arduino.csv already exits.\n",
      "Scrapping topic ASP.NET.\n",
      "File Resultant Data Files/ASP.NET.csv already exits.\n",
      "Scrapping topic Atom.\n",
      "File Resultant Data Files/Atom.csv already exits.\n",
      "Scrapping topic Awesome Lists.\n",
      "File Resultant Data Files/Awesome Lists.csv already exits.\n",
      "Scrapping topic Amazon Web Services.\n",
      "File Resultant Data Files/Amazon Web Services.csv already exits.\n",
      "Scrapping topic Azure.\n",
      "File Resultant Data Files/Azure.csv already exits.\n",
      "Scrapping topic Babel.\n",
      "File Resultant Data Files/Babel.csv already exits.\n",
      "Scrapping topic Bash.\n",
      "File Resultant Data Files/Bash.csv already exits.\n",
      "Scrapping topic Bitcoin.\n",
      "File Resultant Data Files/Bitcoin.csv already exits.\n",
      "Scrapping topic Bootstrap.\n",
      "File Resultant Data Files/Bootstrap.csv already exits.\n",
      "Scrapping topic Bot.\n",
      "File Resultant Data Files/Bot.csv already exits.\n",
      "Scrapping topic C.\n",
      "File Resultant Data Files/C.csv already exits.\n",
      "Scrapping topic Chrome.\n",
      "File Resultant Data Files/Chrome.csv already exits.\n",
      "Scrapping topic Chrome extension.\n",
      "File Resultant Data Files/Chrome extension.csv already exits.\n",
      "Scrapping topic Command line interface.\n",
      "File Resultant Data Files/Command line interface.csv already exits.\n",
      "Scrapping topic Clojure.\n",
      "File Resultant Data Files/Clojure.csv already exits.\n",
      "Scrapping topic Code quality.\n",
      "File Resultant Data Files/Code quality.csv already exits.\n",
      "Scrapping topic Code review.\n",
      "File Resultant Data Files/Code review.csv already exits.\n",
      "Scrapping topic Compiler.\n",
      "File Resultant Data Files/Compiler.csv already exits.\n",
      "Scrapping topic Continuous integration.\n",
      "File Resultant Data Files/Continuous integration.csv already exits.\n",
      "Scrapping topic COVID-19.\n",
      "File Resultant Data Files/COVID-19.csv already exits.\n",
      "Scrapping topic C++.\n",
      "File Resultant Data Files/C++.csv already exits.\n",
      "Scrapping topic Cryptocurrency.\n",
      "File Resultant Data Files/Cryptocurrency.csv already exits.\n",
      "Scrapping topic Crystal.\n",
      "File Resultant Data Files/Crystal.csv already exits.\n",
      "Scrapping topic C#.\n",
      "File Resultant Data Files/C#.csv already exits.\n",
      "Scrapping topic CSS.\n",
      "File Resultant Data Files/CSS.csv already exits.\n",
      "Scrapping topic Data structures.\n",
      "File Resultant Data Files/Data structures.csv already exits.\n",
      "Scrapping topic Data visualization.\n",
      "File Resultant Data Files/Data visualization.csv already exits.\n",
      "Scrapping topic Database.\n",
      "File Resultant Data Files/Database.csv already exits.\n",
      "Scrapping topic Deep learning.\n",
      "File Resultant Data Files/Deep learning.csv already exits.\n",
      "Scrapping topic Dependency management.\n",
      "File Resultant Data Files/Dependency management.csv already exits.\n",
      "Scrapping topic Deployment.\n",
      "File Resultant Data Files/Deployment.csv already exits.\n",
      "Scrapping topic Django.\n",
      "File Resultant Data Files/Django.csv already exits.\n",
      "Scrapping topic Docker.\n",
      "File Resultant Data Files/Docker.csv already exits.\n",
      "Scrapping topic Documentation.\n",
      "File Resultant Data Files/Documentation.csv already exits.\n",
      "Scrapping topic .NET.\n",
      "File Resultant Data Files/.NET.csv already exits.\n",
      "Scrapping topic Electron.\n",
      "File Resultant Data Files/Electron.csv already exits.\n",
      "Scrapping topic Elixir.\n",
      "File Resultant Data Files/Elixir.csv already exits.\n",
      "Scrapping topic Emacs.\n",
      "File Resultant Data Files/Emacs.csv already exits.\n",
      "Scrapping topic Ember.\n",
      "File Resultant Data Files/Ember.csv already exits.\n",
      "Scrapping topic Emoji.\n",
      "File Resultant Data Files/Emoji.csv already exits.\n",
      "Scrapping topic Emulator.\n",
      "File Resultant Data Files/Emulator.csv already exits.\n",
      "Scrapping topic ESLint.\n",
      "File Resultant Data Files/ESLint.csv already exits.\n",
      "Scrapping topic Ethereum.\n",
      "File Resultant Data Files/Ethereum.csv already exits.\n",
      "Scrapping topic Express.\n",
      "File Resultant Data Files/Express.csv already exits.\n",
      "Scrapping topic Firebase.\n",
      "File Resultant Data Files/Firebase.csv already exits.\n",
      "Scrapping topic Firefox.\n",
      "File Resultant Data Files/Firefox.csv already exits.\n",
      "Scrapping topic Flask.\n",
      "File Resultant Data Files/Flask.csv already exits.\n",
      "Scrapping topic Font.\n",
      "File Resultant Data Files/Font.csv already exits.\n",
      "Scrapping topic Framework.\n",
      "File Resultant Data Files/Framework.csv already exits.\n",
      "Scrapping topic Front end.\n",
      "File Resultant Data Files/Front end.csv already exits.\n",
      "Scrapping topic Game engine.\n",
      "File Resultant Data Files/Game engine.csv already exits.\n",
      "Scrapping topic Git.\n",
      "File Resultant Data Files/Git.csv already exits.\n",
      "Scrapping topic GitHub API.\n",
      "File Resultant Data Files/GitHub API.csv already exits.\n",
      "Scrapping topic Go.\n",
      "File Resultant Data Files/Go.csv already exits.\n",
      "Scrapping topic Google.\n",
      "File Resultant Data Files/Google.csv already exits.\n",
      "Scrapping topic Gradle.\n",
      "File Resultant Data Files/Gradle.csv already exits.\n",
      "Scrapping topic GraphQL.\n",
      "File Resultant Data Files/GraphQL.csv already exits.\n",
      "Scrapping topic Gulp.\n",
      "File Resultant Data Files/Gulp.csv already exits.\n",
      "Scrapping topic Hacktoberfest.\n",
      "File Resultant Data Files/Hacktoberfest.csv already exits.\n",
      "Scrapping topic Haskell.\n",
      "File Resultant Data Files/Haskell.csv already exits.\n",
      "Scrapping topic Homebrew.\n",
      "File Resultant Data Files/Homebrew.csv already exits.\n",
      "Scrapping topic Homebridge.\n",
      "File Resultant Data Files/Homebridge.csv already exits.\n",
      "Scrapping topic HTML.\n",
      "File Resultant Data Files/HTML.csv already exits.\n",
      "Scrapping topic HTTP.\n",
      "File Resultant Data Files/HTTP.csv already exits.\n",
      "Scrapping topic Icon font.\n",
      "File Resultant Data Files/Icon font.csv already exits.\n",
      "Scrapping topic iOS.\n",
      "File Resultant Data Files/iOS.csv already exits.\n",
      "Scrapping topic IPFS.\n",
      "File Resultant Data Files/IPFS.csv already exits.\n",
      "Scrapping topic Java.\n",
      "File Resultant Data Files/Java.csv already exits.\n",
      "Scrapping topic JavaScript.\n",
      "File Resultant Data Files/JavaScript.csv already exits.\n",
      "Scrapping topic Jekyll.\n",
      "File Resultant Data Files/Jekyll.csv already exits.\n",
      "Scrapping topic jQuery.\n",
      "File Resultant Data Files/jQuery.csv already exits.\n",
      "Scrapping topic JSON.\n",
      "File Resultant Data Files/JSON.csv already exits.\n",
      "Scrapping topic The Julia Language.\n",
      "File Resultant Data Files/The Julia Language.csv already exits.\n",
      "Scrapping topic Jupyter Notebook.\n",
      "File Resultant Data Files/Jupyter Notebook.csv already exits.\n",
      "Scrapping topic Koa.\n",
      "File Resultant Data Files/Koa.csv already exits.\n",
      "Scrapping topic Kotlin.\n",
      "File Resultant Data Files/Kotlin.csv already exits.\n",
      "Scrapping topic Kubernetes.\n",
      "File Resultant Data Files/Kubernetes.csv already exits.\n",
      "Scrapping topic Laravel.\n",
      "File Resultant Data Files/Laravel.csv already exits.\n",
      "Scrapping topic LaTeX.\n",
      "File Resultant Data Files/LaTeX.csv already exits.\n",
      "Scrapping topic Library.\n",
      "File Resultant Data Files/Library.csv already exits.\n",
      "Scrapping topic Linux.\n",
      "File Resultant Data Files/Linux.csv already exits.\n",
      "Scrapping topic Localization.\n",
      "File Resultant Data Files/Localization.csv already exits.\n",
      "Scrapping topic Lua.\n",
      "File Resultant Data Files/Lua.csv already exits.\n",
      "Scrapping topic Machine learning.\n",
      "File Resultant Data Files/Machine learning.csv already exits.\n",
      "Scrapping topic macOS.\n",
      "File Resultant Data Files/macOS.csv already exits.\n",
      "Scrapping topic Markdown.\n",
      "File Resultant Data Files/Markdown.csv already exits.\n",
      "Scrapping topic Mastodon.\n",
      "File Resultant Data Files/Mastodon.csv already exits.\n",
      "Scrapping topic Material design.\n",
      "File Resultant Data Files/Material design.csv already exits.\n",
      "Scrapping topic MATLAB.\n",
      "File Resultant Data Files/MATLAB.csv already exits.\n",
      "Scrapping topic Maven.\n",
      "File Resultant Data Files/Maven.csv already exits.\n",
      "Scrapping topic Minecraft.\n",
      "File Resultant Data Files/Minecraft.csv already exits.\n",
      "Scrapping topic Mobile.\n",
      "File Resultant Data Files/Mobile.csv already exits.\n",
      "Scrapping topic Monero.\n",
      "File Resultant Data Files/Monero.csv already exits.\n",
      "Scrapping topic MongoDB.\n",
      "File Resultant Data Files/MongoDB.csv already exits.\n",
      "Scrapping topic Mongoose.\n",
      "File Resultant Data Files/Mongoose.csv already exits.\n",
      "Scrapping topic Monitoring.\n",
      "File Resultant Data Files/Monitoring.csv already exits.\n",
      "Scrapping topic MvvmCross.\n",
      "File Resultant Data Files/MvvmCross.csv already exits.\n",
      "Scrapping topic MySQL.\n",
      "File Resultant Data Files/MySQL.csv already exits.\n",
      "Scrapping topic NativeScript.\n",
      "File Resultant Data Files/NativeScript.csv already exits.\n",
      "Scrapping topic Nim.\n",
      "File Resultant Data Files/Nim.csv already exits.\n",
      "Scrapping topic Natural language processing.\n",
      "File Resultant Data Files/Natural language processing.csv already exits.\n",
      "Scrapping topic Node.js.\n",
      "File Resultant Data Files/Node.js.csv already exits.\n",
      "Scrapping topic NoSQL.\n",
      "File Resultant Data Files/NoSQL.csv already exits.\n",
      "Scrapping topic npm.\n",
      "File Resultant Data Files/npm.csv already exits.\n",
      "Scrapping topic Objective-C.\n",
      "File Resultant Data Files/Objective-C.csv already exits.\n",
      "Scrapping topic OpenGL.\n",
      "File Resultant Data Files/OpenGL.csv already exits.\n",
      "Scrapping topic Operating system.\n",
      "File Resultant Data Files/Operating system.csv already exits.\n",
      "Scrapping topic P2P.\n",
      "File Resultant Data Files/P2P.csv already exits.\n",
      "Scrapping topic Package manager.\n",
      "File Resultant Data Files/Package manager.csv already exits.\n",
      "Scrapping topic Parsing.\n",
      "File Resultant Data Files/Parsing.csv already exits.\n",
      "Scrapping topic Perl.\n",
      "File Resultant Data Files/Perl.csv already exits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrapping topic Phaser.\n",
      "File Resultant Data Files/Phaser.csv already exits.\n",
      "Scrapping topic PHP.\n",
      "File Resultant Data Files/PHP.csv already exits.\n",
      "Scrapping topic PICO-8.\n",
      "File Resultant Data Files/PICO-8.csv already exits.\n",
      "Scrapping topic Pixel Art.\n",
      "File Resultant Data Files/Pixel Art.csv already exits.\n",
      "Scrapping topic PostgreSQL.\n",
      "File Resultant Data Files/PostgreSQL.csv already exits.\n",
      "Scrapping topic Project management.\n",
      "File Resultant Data Files/Project management.csv already exits.\n",
      "Scrapping topic Publishing.\n",
      "File Resultant Data Files/Publishing.csv already exits.\n",
      "Scrapping topic PWA.\n",
      "File Resultant Data Files/PWA.csv already exits.\n",
      "Scrapping topic Python.\n",
      "File Resultant Data Files/Python.csv already exits.\n",
      "Scrapping topic Qt.\n",
      "File Resultant Data Files/Qt.csv already exits.\n",
      "Scrapping topic R.\n",
      "File Resultant Data Files/R.csv already exits.\n",
      "Scrapping topic Rails.\n",
      "File Resultant Data Files/Rails.csv already exits.\n",
      "Scrapping topic Raspberry Pi.\n",
      "File Resultant Data Files/Raspberry Pi.csv already exits.\n",
      "Scrapping topic Ratchet.\n",
      "File Resultant Data Files/Ratchet.csv already exits.\n",
      "Scrapping topic React.\n",
      "File Resultant Data Files/React.csv already exits.\n",
      "Scrapping topic React Native.\n",
      "File Resultant Data Files/React Native.csv already exits.\n",
      "Scrapping topic ReactiveUI.\n",
      "File Resultant Data Files/ReactiveUI.csv already exits.\n",
      "Scrapping topic Redux.\n",
      "File Resultant Data Files/Redux.csv already exits.\n",
      "Scrapping topic REST API.\n",
      "File Resultant Data Files/REST API.csv already exits.\n",
      "Scrapping topic Ruby.\n",
      "File Resultant Data Files/Ruby.csv already exits.\n",
      "Scrapping topic Rust.\n",
      "File Resultant Data Files/Rust.csv already exits.\n",
      "Scrapping topic Sass.\n",
      "File Resultant Data Files/Sass.csv already exits.\n",
      "Scrapping topic Scala.\n",
      "File Resultant Data Files/Scala.csv already exits.\n",
      "Scrapping topic scikit-learn.\n",
      "File Resultant Data Files/scikit-learn.csv already exits.\n",
      "Scrapping topic Software-defined networking.\n",
      "File Resultant Data Files/Software-defined networking.csv already exits.\n",
      "Scrapping topic Security.\n",
      "File Resultant Data Files/Security.csv already exits.\n",
      "Scrapping topic Server.\n",
      "File Resultant Data Files/Server.csv already exits.\n",
      "Scrapping topic Serverless.\n",
      "File Resultant Data Files/Serverless.csv already exits.\n",
      "Scrapping topic Shell.\n",
      "File Resultant Data Files/Shell.csv already exits.\n",
      "Scrapping topic Sketch.\n",
      "File Resultant Data Files/Sketch.csv already exits.\n",
      "Scrapping topic SpaceVim.\n",
      "File Resultant Data Files/SpaceVim.csv already exits.\n",
      "Scrapping topic Spring Boot.\n",
      "File Resultant Data Files/Spring Boot.csv already exits.\n",
      "Scrapping topic SQL.\n",
      "File Resultant Data Files/SQL.csv already exits.\n",
      "Scrapping topic Storybook.\n",
      "File Resultant Data Files/Storybook.csv already exits.\n",
      "Scrapping topic Support.\n",
      "File Resultant Data Files/Support.csv already exits.\n",
      "Scrapping topic Swift.\n",
      "File Resultant Data Files/Swift.csv already exits.\n",
      "Scrapping topic Symfony.\n",
      "File Resultant Data Files/Symfony.csv already exits.\n",
      "Scrapping topic Telegram.\n",
      "File Resultant Data Files/Telegram.csv already exits.\n",
      "Scrapping topic Tensorflow.\n",
      "File Resultant Data Files/Tensorflow.csv already exits.\n",
      "Scrapping topic Terminal.\n",
      "File Resultant Data Files/Terminal.csv already exits.\n",
      "Scrapping topic Terraform.\n",
      "File Resultant Data Files/Terraform.csv already exits.\n",
      "Scrapping topic Testing.\n",
      "File Resultant Data Files/Testing.csv already exits.\n",
      "Scrapping topic Twitter.\n",
      "File Resultant Data Files/Twitter.csv already exits.\n",
      "Scrapping topic TypeScript.\n",
      "File Resultant Data Files/TypeScript.csv already exits.\n",
      "Scrapping topic Ubuntu.\n",
      "File Resultant Data Files/Ubuntu.csv already exits.\n",
      "Scrapping topic Unity.\n",
      "File Resultant Data Files/Unity.csv already exits.\n",
      "Scrapping topic Unreal Engine.\n",
      "File Resultant Data Files/Unreal Engine.csv already exits.\n",
      "Scrapping topic Vagrant.\n",
      "File Resultant Data Files/Vagrant.csv already exits.\n",
      "Scrapping topic Vim.\n",
      "File Resultant Data Files/Vim.csv already exits.\n",
      "Scrapping topic Virtual reality.\n",
      "File Resultant Data Files/Virtual reality.csv already exits.\n",
      "Scrapping topic Vue.js.\n",
      "File Resultant Data Files/Vue.js.csv already exits.\n",
      "Scrapping topic Wagtail.\n",
      "File Resultant Data Files/Wagtail.csv already exits.\n",
      "Scrapping topic Web Components.\n",
      "File Resultant Data Files/Web Components.csv already exits.\n",
      "Scrapping topic Web app.\n",
      "File Resultant Data Files/Web app.csv already exits.\n",
      "Scrapping topic Webpack.\n",
      "File Resultant Data Files/Webpack.csv already exits.\n",
      "Scrapping topic Windows.\n",
      "File Resultant Data Files/Windows.csv already exits.\n",
      "Scrapping topic WordPlate.\n",
      "File Resultant Data Files/WordPlate.csv already exits.\n",
      "Scrapping topic WordPress.\n",
      "File Resultant Data Files/WordPress.csv already exits.\n",
      "Scrapping topic Xamarin.\n",
      "File Resultant Data Files/Xamarin.csv already exits.\n",
      "Scrapping topic XML.\n",
      "File Resultant Data Files/XML.csv already exits.\n"
     ]
    }
   ],
   "source": [
    "scrape_topics_repos()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Helper site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://jovian.ai/aakashns-6l3/scraping-github-topics-repositories"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
