{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import bs4 as bs\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a single function to:\n",
    "1. Get the list of topics from the topics page\n",
    "2. Get list of top repos from the individual topic pages\n",
    "3. For each topic create a csv of the top repos for the topic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_title(doc):\n",
    "    selection_class = 'f3 lh-condensed mb-0 mt-1 Link--primary'\n",
    "    topic_title_tag = doc.find_all('p',{'class': selection_class })\n",
    "    \n",
    "    topic_title = []\n",
    "    for tag in topic_title_tag:\n",
    "        topic_title.append(tag.text)\n",
    "    return topic_title\n",
    "\n",
    "def get_topic_desc(doc):\n",
    "    desc_selector = 'f5 color-fg-muted mb-0 mt-1'\n",
    "    topic_desc_tag = doc.find_all('p',{'class':desc_selector})\n",
    "    topic_desc = []\n",
    "    for desc in topic_desc_tag:\n",
    "        topic_desc.append(desc.text.strip())\n",
    "    return topic_desc\n",
    "    \n",
    "    \n",
    "def get_topic_url(doc):\n",
    "    base_url = \"https://github.com\"\n",
    "    url_selector = 'no-underline flex-1 d-flex flex-column'\n",
    "    topic_link_tag = doc.find_all('a',{'class':url_selector})        \n",
    "    topic_urls = []\n",
    "    \n",
    "    for url in  topic_link_tag:\n",
    "        topic_urls.append(base_url+url['href'])\n",
    "    return topic_urls\n",
    "        \n",
    "def scrape_topics(num):\n",
    "    topic_url = 'https://github.com/topics?page={}'.format(num)\n",
    "    response = requests.get(topic_url)\n",
    "    if response.status_code !=200:\n",
    "        print(\"Process Stops restarting..........\")\n",
    "        !scrape_topics_repos()\n",
    "#         raise Exception('Failed to load the page {}'.format(topic_url))\n",
    "        \n",
    "    doc = bs.BeautifulSoup(response.text,'html.parser')\n",
    "    topics_dict = {\n",
    "        'title' : get_topic_title(doc),\n",
    "        'description' : get_topic_desc(doc),\n",
    "        'url' : get_topic_url(doc),\n",
    "        \n",
    "    }\n",
    "#     print(topics_dict)\n",
    "    return pd.DataFrame(topics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_page(topic_url):\n",
    "    response = requests.get(topic_url)\n",
    "    if response.status_code !=200:\n",
    "        raise Exception('Failed to load the page {}'.format(topic_url))\n",
    "    topic_doc = bs.BeautifulSoup(response.text,'html.parser')\n",
    "    return topic_doc\n",
    "\n",
    "def get_repo_info(h3_tag, star_tags):\n",
    "    #gives all info about repository\n",
    "    base_url = \"https://github.com\"\n",
    "    a_tags = h3_tag.find_all('a')\n",
    "    username = a_tags[0].text.strip()\n",
    "    repo_name = a_tags[1].text.strip()\n",
    "    repo_url = repo_url = base_url + a_tags[1]['href']\n",
    "    star_count = parse_star_count(star_tags.text)\n",
    "    return username, repo_name, star_count, repo_url\n",
    "\n",
    "def parse_star_count(stars_count):\n",
    "    stars_str = stars_count.strip()\n",
    "    if stars_str[-1] == 'k':\n",
    "        return int(float(stars_str[:-1])*1000)\n",
    "    return (int(stars_str))\n",
    "        \n",
    "\n",
    "def get_topic_repos(topic_doc):\n",
    "    \n",
    "#     get h3 tag for repo name, url, etc.\n",
    "    h3_selection_class = 'f3 color-fg-muted text-normal lh-condensed'\n",
    "    repo_tags = topic_doc.find_all('h3',{'class': h3_selection_class})\n",
    "    \n",
    "#     get star tags\n",
    "    star_selector = 'Counter js-social-count'\n",
    "    star_tags = topic_doc.find_all('span',{'class': star_selector})\n",
    "    \n",
    "#     get repo info\n",
    "    topic_repos_dict = {\n",
    "        'username':[],\n",
    "        'repo_name':[],\n",
    "        'stars': [],\n",
    "        'repo_url':[]\n",
    "    }\n",
    "    for i in range (len(repo_tags)):\n",
    "        repo_info = get_repo_info(repo_tags[i],star_tags[i])\n",
    "        topic_repos_dict['username'].append(repo_info[0])\n",
    "        topic_repos_dict['repo_name'].append(repo_info[1])\n",
    "        topic_repos_dict['stars'].append(repo_info[2])\n",
    "        topic_repos_dict['repo_url'].append(repo_info[3])\n",
    "        \n",
    "#     put all in dataframe\n",
    "    topic_repos = pd.DataFrame(topic_repos_dict)\n",
    "    return topic_repos\n",
    "\n",
    "def scrape_topic(topic_url,path):\n",
    "\n",
    "    if os.path.exists(path):\n",
    "        print(\"File {} already exits.\".format(path))\n",
    "        return\n",
    "    topic_df = get_topic_repos(get_topic_page(topic_url))\n",
    "    topic_df.to_csv(path,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_topics_repos():\n",
    "    for i in range(1,7):\n",
    "        topics_df = scrape_topics(i)\n",
    "\n",
    "        os.makedirs('Final_data_file',exist_ok = True)\n",
    "\n",
    "        for index,row in topics_df.iterrows():\n",
    "            print(\"Scrapping topic {}.\".format(row['title']))\n",
    "            scrape_topic(row['url'],'Final_data_file/{}.csv'.format(row['title']))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrapping topic 3D.\n",
      "File Final_data_file/3D.csv already exits.\n",
      "Scrapping topic Ajax.\n",
      "File Final_data_file/Ajax.csv already exits.\n",
      "Scrapping topic Algorithm.\n",
      "File Final_data_file/Algorithm.csv already exits.\n",
      "Scrapping topic Amp.\n",
      "File Final_data_file/Amp.csv already exits.\n",
      "Scrapping topic Android.\n",
      "File Final_data_file/Android.csv already exits.\n",
      "Scrapping topic Angular.\n",
      "File Final_data_file/Angular.csv already exits.\n",
      "Scrapping topic Ansible.\n",
      "File Final_data_file/Ansible.csv already exits.\n",
      "Scrapping topic API.\n",
      "File Final_data_file/API.csv already exits.\n",
      "Scrapping topic Arduino.\n",
      "File Final_data_file/Arduino.csv already exits.\n",
      "Scrapping topic ASP.NET.\n",
      "File Final_data_file/ASP.NET.csv already exits.\n",
      "Scrapping topic Atom.\n",
      "File Final_data_file/Atom.csv already exits.\n",
      "Scrapping topic Awesome Lists.\n",
      "File Final_data_file/Awesome Lists.csv already exits.\n",
      "Scrapping topic Amazon Web Services.\n",
      "File Final_data_file/Amazon Web Services.csv already exits.\n",
      "Scrapping topic Azure.\n",
      "File Final_data_file/Azure.csv already exits.\n",
      "Scrapping topic Babel.\n",
      "File Final_data_file/Babel.csv already exits.\n",
      "Scrapping topic Bash.\n",
      "File Final_data_file/Bash.csv already exits.\n",
      "Scrapping topic Bitcoin.\n",
      "File Final_data_file/Bitcoin.csv already exits.\n",
      "Scrapping topic Bootstrap.\n",
      "File Final_data_file/Bootstrap.csv already exits.\n",
      "Scrapping topic Bot.\n",
      "File Final_data_file/Bot.csv already exits.\n",
      "Scrapping topic C.\n",
      "File Final_data_file/C.csv already exits.\n",
      "Scrapping topic Chrome.\n",
      "File Final_data_file/Chrome.csv already exits.\n",
      "Scrapping topic Chrome extension.\n",
      "File Final_data_file/Chrome extension.csv already exits.\n",
      "Scrapping topic Command line interface.\n",
      "File Final_data_file/Command line interface.csv already exits.\n",
      "Scrapping topic Clojure.\n",
      "File Final_data_file/Clojure.csv already exits.\n",
      "Scrapping topic Code quality.\n",
      "File Final_data_file/Code quality.csv already exits.\n",
      "Scrapping topic Code review.\n",
      "File Final_data_file/Code review.csv already exits.\n",
      "Scrapping topic Compiler.\n",
      "File Final_data_file/Compiler.csv already exits.\n",
      "Scrapping topic Continuous integration.\n",
      "File Final_data_file/Continuous integration.csv already exits.\n",
      "Scrapping topic COVID-19.\n",
      "File Final_data_file/COVID-19.csv already exits.\n",
      "Scrapping topic C++.\n",
      "File Final_data_file/C++.csv already exits.\n",
      "Scrapping topic Cryptocurrency.\n",
      "File Final_data_file/Cryptocurrency.csv already exits.\n",
      "Scrapping topic Crystal.\n",
      "File Final_data_file/Crystal.csv already exits.\n",
      "Scrapping topic C#.\n",
      "File Final_data_file/C#.csv already exits.\n",
      "Scrapping topic CSS.\n",
      "File Final_data_file/CSS.csv already exits.\n",
      "Scrapping topic Data structures.\n",
      "File Final_data_file/Data structures.csv already exits.\n",
      "Scrapping topic Data visualization.\n",
      "File Final_data_file/Data visualization.csv already exits.\n",
      "Scrapping topic Database.\n",
      "File Final_data_file/Database.csv already exits.\n",
      "Scrapping topic Deep learning.\n",
      "File Final_data_file/Deep learning.csv already exits.\n",
      "Scrapping topic Dependency management.\n",
      "File Final_data_file/Dependency management.csv already exits.\n",
      "Scrapping topic Deployment.\n",
      "File Final_data_file/Deployment.csv already exits.\n",
      "Scrapping topic Django.\n",
      "File Final_data_file/Django.csv already exits.\n",
      "Scrapping topic Docker.\n",
      "File Final_data_file/Docker.csv already exits.\n",
      "Scrapping topic Documentation.\n",
      "File Final_data_file/Documentation.csv already exits.\n",
      "Scrapping topic .NET.\n",
      "File Final_data_file/.NET.csv already exits.\n",
      "Scrapping topic Electron.\n",
      "File Final_data_file/Electron.csv already exits.\n",
      "Scrapping topic Elixir.\n",
      "File Final_data_file/Elixir.csv already exits.\n",
      "Scrapping topic Emacs.\n",
      "File Final_data_file/Emacs.csv already exits.\n",
      "Scrapping topic Ember.\n",
      "File Final_data_file/Ember.csv already exits.\n",
      "Scrapping topic Emoji.\n",
      "File Final_data_file/Emoji.csv already exits.\n",
      "Scrapping topic Emulator.\n",
      "File Final_data_file/Emulator.csv already exits.\n",
      "Scrapping topic ESLint.\n",
      "File Final_data_file/ESLint.csv already exits.\n",
      "Scrapping topic Ethereum.\n",
      "File Final_data_file/Ethereum.csv already exits.\n",
      "Scrapping topic Express.\n",
      "File Final_data_file/Express.csv already exits.\n",
      "Scrapping topic Firebase.\n",
      "File Final_data_file/Firebase.csv already exits.\n",
      "Scrapping topic Firefox.\n",
      "File Final_data_file/Firefox.csv already exits.\n",
      "Scrapping topic Flask.\n",
      "File Final_data_file/Flask.csv already exits.\n",
      "Scrapping topic Font.\n",
      "File Final_data_file/Font.csv already exits.\n",
      "Scrapping topic Framework.\n",
      "File Final_data_file/Framework.csv already exits.\n",
      "Scrapping topic Front end.\n",
      "File Final_data_file/Front end.csv already exits.\n",
      "Scrapping topic Game engine.\n",
      "File Final_data_file/Game engine.csv already exits.\n",
      "Scrapping topic Git.\n",
      "File Final_data_file/Git.csv already exits.\n",
      "Scrapping topic GitHub API.\n",
      "File Final_data_file/GitHub API.csv already exits.\n",
      "Scrapping topic Go.\n",
      "File Final_data_file/Go.csv already exits.\n",
      "Scrapping topic Google.\n",
      "File Final_data_file/Google.csv already exits.\n",
      "Scrapping topic Gradle.\n",
      "File Final_data_file/Gradle.csv already exits.\n",
      "Scrapping topic GraphQL.\n",
      "File Final_data_file/GraphQL.csv already exits.\n",
      "Scrapping topic Gulp.\n",
      "File Final_data_file/Gulp.csv already exits.\n",
      "Scrapping topic Hacktoberfest.\n",
      "File Final_data_file/Hacktoberfest.csv already exits.\n",
      "Scrapping topic Haskell.\n",
      "File Final_data_file/Haskell.csv already exits.\n",
      "Scrapping topic Homebrew.\n",
      "File Final_data_file/Homebrew.csv already exits.\n",
      "Scrapping topic Homebridge.\n",
      "File Final_data_file/Homebridge.csv already exits.\n",
      "Scrapping topic HTML.\n",
      "File Final_data_file/HTML.csv already exits.\n",
      "Scrapping topic HTTP.\n",
      "File Final_data_file/HTTP.csv already exits.\n",
      "Scrapping topic Icon font.\n",
      "File Final_data_file/Icon font.csv already exits.\n",
      "Scrapping topic iOS.\n",
      "File Final_data_file/iOS.csv already exits.\n",
      "Scrapping topic IPFS.\n",
      "File Final_data_file/IPFS.csv already exits.\n",
      "Scrapping topic Java.\n",
      "File Final_data_file/Java.csv already exits.\n",
      "Scrapping topic JavaScript.\n",
      "File Final_data_file/JavaScript.csv already exits.\n",
      "Scrapping topic Jekyll.\n",
      "File Final_data_file/Jekyll.csv already exits.\n",
      "Scrapping topic jQuery.\n",
      "File Final_data_file/jQuery.csv already exits.\n",
      "Scrapping topic JSON.\n",
      "File Final_data_file/JSON.csv already exits.\n",
      "Scrapping topic The Julia Language.\n",
      "File Final_data_file/The Julia Language.csv already exits.\n",
      "Scrapping topic Jupyter Notebook.\n",
      "File Final_data_file/Jupyter Notebook.csv already exits.\n",
      "Scrapping topic Koa.\n",
      "File Final_data_file/Koa.csv already exits.\n",
      "Scrapping topic Kotlin.\n",
      "File Final_data_file/Kotlin.csv already exits.\n",
      "Scrapping topic Kubernetes.\n",
      "File Final_data_file/Kubernetes.csv already exits.\n",
      "Scrapping topic Laravel.\n",
      "File Final_data_file/Laravel.csv already exits.\n",
      "Scrapping topic LaTeX.\n",
      "File Final_data_file/LaTeX.csv already exits.\n",
      "Scrapping topic Library.\n",
      "File Final_data_file/Library.csv already exits.\n",
      "Scrapping topic Linux.\n",
      "File Final_data_file/Linux.csv already exits.\n",
      "Scrapping topic Localization.\n",
      "File Final_data_file/Localization.csv already exits.\n",
      "Scrapping topic Lua.\n",
      "File Final_data_file/Lua.csv already exits.\n",
      "Scrapping topic Machine learning.\n",
      "File Final_data_file/Machine learning.csv already exits.\n",
      "Scrapping topic macOS.\n",
      "File Final_data_file/macOS.csv already exits.\n",
      "Scrapping topic Markdown.\n",
      "File Final_data_file/Markdown.csv already exits.\n",
      "Scrapping topic Mastodon.\n",
      "File Final_data_file/Mastodon.csv already exits.\n",
      "Scrapping topic Material design.\n",
      "File Final_data_file/Material design.csv already exits.\n",
      "Scrapping topic MATLAB.\n",
      "File Final_data_file/MATLAB.csv already exits.\n",
      "Scrapping topic Maven.\n",
      "File Final_data_file/Maven.csv already exits.\n",
      "Scrapping topic Minecraft.\n",
      "File Final_data_file/Minecraft.csv already exits.\n",
      "Scrapping topic Mobile.\n",
      "File Final_data_file/Mobile.csv already exits.\n",
      "Scrapping topic Monero.\n",
      "File Final_data_file/Monero.csv already exits.\n",
      "Scrapping topic MongoDB.\n",
      "File Final_data_file/MongoDB.csv already exits.\n",
      "Scrapping topic Mongoose.\n",
      "File Final_data_file/Mongoose.csv already exits.\n",
      "Scrapping topic Monitoring.\n",
      "File Final_data_file/Monitoring.csv already exits.\n",
      "Scrapping topic MvvmCross.\n",
      "File Final_data_file/MvvmCross.csv already exits.\n",
      "Scrapping topic MySQL.\n",
      "File Final_data_file/MySQL.csv already exits.\n",
      "Scrapping topic NativeScript.\n",
      "File Final_data_file/NativeScript.csv already exits.\n",
      "Scrapping topic Nim.\n",
      "File Final_data_file/Nim.csv already exits.\n",
      "Scrapping topic Natural language processing.\n",
      "File Final_data_file/Natural language processing.csv already exits.\n",
      "Scrapping topic Node.js.\n",
      "File Final_data_file/Node.js.csv already exits.\n",
      "Scrapping topic NoSQL.\n",
      "File Final_data_file/NoSQL.csv already exits.\n",
      "Scrapping topic npm.\n",
      "File Final_data_file/npm.csv already exits.\n",
      "Scrapping topic Objective-C.\n",
      "File Final_data_file/Objective-C.csv already exits.\n",
      "Scrapping topic OpenGL.\n",
      "File Final_data_file/OpenGL.csv already exits.\n",
      "Scrapping topic Operating system.\n",
      "File Final_data_file/Operating system.csv already exits.\n",
      "Scrapping topic P2P.\n",
      "File Final_data_file/P2P.csv already exits.\n",
      "Scrapping topic Package manager.\n",
      "File Final_data_file/Package manager.csv already exits.\n",
      "Scrapping topic Parsing.\n",
      "File Final_data_file/Parsing.csv already exits.\n",
      "Scrapping topic Perl.\n",
      "File Final_data_file/Perl.csv already exits.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrapping topic Phaser.\n",
      "File Final_data_file/Phaser.csv already exits.\n",
      "Scrapping topic PHP.\n",
      "File Final_data_file/PHP.csv already exits.\n",
      "Scrapping topic PICO-8.\n",
      "File Final_data_file/PICO-8.csv already exits.\n",
      "Scrapping topic Pixel Art.\n",
      "File Final_data_file/Pixel Art.csv already exits.\n",
      "Scrapping topic PostgreSQL.\n",
      "File Final_data_file/PostgreSQL.csv already exits.\n",
      "Scrapping topic Project management.\n",
      "File Final_data_file/Project management.csv already exits.\n",
      "Scrapping topic Publishing.\n",
      "File Final_data_file/Publishing.csv already exits.\n",
      "Scrapping topic PWA.\n",
      "File Final_data_file/PWA.csv already exits.\n",
      "Scrapping topic Python.\n",
      "File Final_data_file/Python.csv already exits.\n",
      "Scrapping topic Qt.\n",
      "File Final_data_file/Qt.csv already exits.\n",
      "Scrapping topic R.\n",
      "File Final_data_file/R.csv already exits.\n",
      "Scrapping topic Rails.\n",
      "File Final_data_file/Rails.csv already exits.\n",
      "Scrapping topic Raspberry Pi.\n",
      "Scrapping topic Ratchet.\n",
      "Scrapping topic React.\n",
      "Scrapping topic React Native.\n",
      "Scrapping topic ReactiveUI.\n",
      "Scrapping topic Redux.\n",
      "Scrapping topic REST API.\n",
      "Scrapping topic Ruby.\n",
      "Scrapping topic Rust.\n",
      "Scrapping topic Sass.\n",
      "Scrapping topic Scala.\n",
      "Scrapping topic scikit-learn.\n",
      "Scrapping topic Software-defined networking.\n",
      "Scrapping topic Security.\n",
      "Scrapping topic Server.\n",
      "Scrapping topic Serverless.\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Failed to load the page https://github.com/topics/serverless",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-ac99c06d7fcd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscrape_topics_repos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-e0e5e230a816>\u001b[0m in \u001b[0;36mscrape_topics_repos\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtopics_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Scrapping topic {}.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'title'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0mscrape_topic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'url'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Final_data_file/{}.csv'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'title'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-c5e4aa9b86db>\u001b[0m in \u001b[0;36mscrape_topic\u001b[1;34m(topic_url, path)\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"File {} already exits.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     \u001b[0mtopic_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_topic_repos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_topic_page\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[0mtopic_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-c5e4aa9b86db>\u001b[0m in \u001b[0;36mget_topic_page\u001b[1;34m(topic_url)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m!=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Failed to load the page {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mtopic_doc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtopic_doc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Failed to load the page https://github.com/topics/serverless"
     ]
    }
   ],
   "source": [
    "scrape_topics_repos()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Helper site"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://jovian.ai/aakashns-6l3/scraping-github-topics-repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
